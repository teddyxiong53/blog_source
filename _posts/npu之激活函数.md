---
title: npu之激活函数
date: 2021-09-28 15:16:33
tags:
	- npu

---

--

什么是激活函数？

神经网络中的每个神经元节点接受上一层神经元的输出值作为本神经元的输入值，

并将输入值传递给下一层，

输入层神经元节点会将输入属性值直接传递给下一层（隐层或输出层）。

在多层神经网络中，**上层节点的输出和下层节点的输入之间具有一个函数关系**，这个函数称为激活函数（又称激励函数）。



![这里写图片描述](../images/random_name/20170107175151314)



如果不用激励函数（其实相当于激励函数是f(x) = x），

在这种情况下你每一层节点的输入都是上层输出的线性函数，

很容易验证，无论你神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，

这种情况就是最原始的感知机（Perceptron）了，

那么网络的逼近能力就相当有限。

正因为上面的原因，我们决定引入非线性函数作为激励函数，

这样深层神经网络表达能力就更加强大（不再是输入的线性组合，而是几乎可以逼近任意函数）。

早期研究神经网络主要采用sigmoid函数或者tanh函数，输出有界，很容易充当下一层的输入。



参考资料

1、

https://blog.csdn.net/tyhj_sf/article/details/79932893
---
title: keras之各种优化器
date: 2021-09-29 16:19:33
tags:
	- npu

---

--

Adam 算法同时获得了 AdaGrad 和 RMSProp 算法的优点。

Adam 不仅如 RMSProp 算法那样基于一阶矩均值计算适应性参数学习率，

它同时还充分利用了梯度的二阶矩均值。



参考资料

1、


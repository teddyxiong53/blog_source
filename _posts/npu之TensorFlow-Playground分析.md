---
title: npu之TensorFlow-Playground分析
date: 2021-09-29 10:51:33
tags:
	- npu

---

--

地址在这里

https://playground.tensorflow.org/

我一开始看这个，没有搞清楚具体是什么意思。

现在回过头来看看。

在一篇讲全连接神经网络的文章里，提到了这个playground。

这个展示的就是一个全连接的神经网络。

输入的X1和X2，表示零件的重量和长度，绘制到二维平面里。

只要长度和重量都在某个范围内的才是合格的零件。否则不合格。

这个是一个二分类问题。



https://www.zhihu.com/question/42995089



我们的目标就是通过这些特征的分布组合将两类数据（蓝色和黄色） 区分开， 这就是训练的目的。



我们可以设置多个隐藏层， 也可以为一个隐藏层设置多个神经元。

 一般来讲， 隐含层越多， 衍生出的特征类型也就越丰富， 对于分类的效果也会越好，

 但不是越多越好， 层数多了训练的速度会变慢， 同时收敛的效果不一定会更好。

在此我们设置一个隐藏层， 三个神经元。



由此可以看出， 增加特征有助于训练的速度。



PlayGround页面如图所示，主要分为DATA（数据），FEATURES（特征），HIDDEN LAYERS（隐含层），OUTPUT（输出层）。

这里的数据怎么理解？



**小白：能不能具体说一下FEATURES（特征）是什么意思？**

答：这是指的在训练网络时，是否需要给网络输入特征。举个很简单的例子，如果你在描述一个人的时候，你会用一些最能够区分他和其他人的特征来描述这个人。我们在这里说的特征，也是一个意思。即我们找到的，能够最大限度描述输入数据特性的那些东西（“东西”可以用函数或者参数值来表示。）现在回去看截屏中可选择的FEATURES，这些数据都为二维数据，X1代表横轴坐标值，X2代表纵轴坐标值，知道这个之后，其余的特征值就很容易懂啦。

根据不同的问题，我们需要输入不同的特征。

如上图这种复杂的分类问题，仅仅X1 , X2, X12, X21这样**单一维度的特征**可能不足以做出好的模型，

这时候我们就会考虑X1X2这样的交叉特征了。

咱们也可以限制特征，让神经网络自己通过不断的迭代，修改神经元的权重，从而自己“学习”到有用的特征。

在实际应用中，很多图像识别问题已经**可以做到不需要人为进行特征提取，直接对原始图片进行操作。**



懂了。

主要是B站同济子豪兄的视频解释帮助理解了很多。



参考资料

1、

https://blog.csdn.net/kuweicai/article/details/79783083

2、谁能详细讲解一下TensorFlow Playground所展示的神经网络的概念？

https://www.zhihu.com/question/42995089

3、深度学习与新一代人工智能科研教学一体化实验平台

https://www.080910t.com/about/ai-demo/

4、《使用Tensorflow PlayGround理解神经网络》

http://www.china-cia.org.cn/home/WorkDetail?id=5b35a629a8a9701a0c3aff96

5、

这个解决了几个疑问点。

https://cloud.tencent.com/developer/article/1135361
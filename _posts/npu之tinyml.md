---
title: npu之tinyml
date: 2021-08-19 19:26:33
tags:
	- npu

---

--

tinyml是一本书的名字，讲的是在stm32 F4这种soc运行TensorFlow。



Machine Learning (ML) 这一个学科，在学术界有 40 年左右的历史，

但是前面的 30 多年研究，只是在学术上有一些突破。

 

真正让 ML 从学界走入产业界的划时代改革的里程碑，

源于 2010 年 ImageNet 挑战赛 (ILSVRC)。

2012 年，Hiton (ML 业界元老级人物) 课题组首次参加 ImageNet 图像识别比赛，

AlexNet 夺得冠军，并碾压了第二名 (SVM) 的分类性能。

ML 在工业应用的热情在这一年被彻底点燃。



ML 最近几年已经在工业、消费领域获得了大量的应用，

随着云资源的不断完善，研发了更多的激动人心的 AI 模型。

云端 AI 的应用，已经获得长足的进步。

 

在 ML 的工业应用发展的这几年，物联网也处于快速处在发展期。

从最早的智能家居，到现在遍地的物联网智能设备。

AI 应用逐步从云端走向了设备端，现在设备端的 AI 应用已经占了很大的比例，

手机上 AI 的应用已经非常普遍。

 

但是，在物联网世界里，有数以亿计的体积小、功耗低、资源受限的设备支撑着物联网应用。

如何在超低功耗 (mV 功率范围) 的设备上运行人工智能应用，

同时又要满足设备长时间低功耗的运行 AI 应用的需求，已经形成了一个新的课题。



TinyML 指的是在 mW 功率的微处理器上，实现机器学习的方法、工具和技术。

它连接了物联网设备，边缘计算和机器学习。

 

TinyML 基金会在 2019 年组织了第一届峰会，这届峰会的成果如下：

1、TinyML 的技术硬件已经进入了实用性的阶段；

2、算法，网络以及低于 100KB 的 ML 模型，已经取得重大突破；

3、视觉，音频的低功耗需求快速增长。



两位作者中的一位侧重于物联网上的 AI 技术研发，

另一位则侧重于运用 AI 技术去实现工业化，

他们强强联合出版了这本书，

带我们进一步探索物联网端 AI 的所有技术环节工业化实现，

原汁原味的体现了利用 Google 的技术去促进发展的思考脉络。



作为开发环境，我们只需要在电脑上用 USB 接口实现外设接入就行了。

当然根据每一个读者的习惯，可以用自己所熟悉的编译工具来编译这个环境，

所有的这些代码都可以在 Windows，Linux 或者 macOS 上运行。

当然，已经训练出来许多模型在 Google Cloud 中可以下载。

**也可以用 Google Colab 来运行所有的代码。就不必要去担心需要拥有独特的硬件开发环境。**



这本书所有的项目是依赖于 TensorFlow Lite 在微控制器上的开发框架，所依赖的硬件环境，只有几十 kb 左右的存储空间。

项目
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro

# 项目流程

实现基于微控制器的 ML 项目开发流程如下所示：

1、获得简单数据集

2、训练深度学习模型

3、评估模型性能

4、转换成设备上运行的模型

5、将代码转换成二进制文件

6、部署二进制文件到微控制器



我们分享的 Hello World 示例，是用数学中的最基本的sine函数为原型，用 ML 的方式去预测数据。

我们的目标是，如果有一个 x 值，我们能够预测出 x 的 sin 值 y。

在真实的环境中，用数学计算的方法可以更快速的得到结果。

这个例子是用 ML 的方法去实现预测，从而了解 ML 的整个流程。



配置开发环境，所用的编程语言当然是当之无愧的 Python，

这是现在使用最广泛的，运用于科学、数学、以及 AI 领域的编程语言。

版本为 3.x Python 可以在命令行下运行，

但是还是推荐用 Jupyter Notebook 来开发，

它的好处是可以把代码、文档、还有图片放在一起，既能当教程，又能分步运行。


https://github.com/tensorflow/tflite-micro



分布最广的物联网设备往往体积很小、电量有限。

它们被作为终端硬件，通过嵌入式传感器采集各种数据；计算能力有限，对功耗极为敏感。

这类设备也能实现机器学习吗？

一个趋势是，人工智能AI正在加快速度从“云端”走向“边缘”，进入到越来越小的物联网设备中。

在终端和边缘侧的微处理器上，实现的机器学习过程，被称为微型机器学习，即TinyML。



TinyML是不同技术领域和推动因素的交集，它位于**物联网设备、机器学习和边缘计算之间的结合部**，并因为多种驱动力的综合作用，进展很快

![一文读懂即将引爆的TinyML：在边缘侧实现超低功耗机器学习](../images/random_name/20200223195922.png)



TinyML 2019峰会共吸引了来自90多家企业的数百名工程师参与，而本届峰会的盛况更是空前，并且得出了很多重要结论：

　　• 对于很多应用场景，TinyML技术和硬件已经进化到实用性较强的阶段；

　　• 无论是算法、网络，还是低于100KB的ML模型，都取得了重大突破；

　　• 视觉和音频领域的低功耗需求快速增长。

无论何时何地，数据都需要即时可用，这一趋势越来越明显。

全球各行各业都在经历由这种需求推动的“数字化转型”。

根据IDC的分析，到2025年，全球创建的数据中，超过四分之一的数据在本质上都是实时数据，

而物联网实时数据将占这部分数据的95%以上。

目前存在的机器学习可以划分为3种形态，云端ML、边缘ML和TinyML。**TinyML正是针对占比超过95%以上的物联网实时数据处理场景。**



再看TinyML的发展现状，从算法、软件、硬件这三个维度分析，TinyML已经进化到“足够好”，可以实际应用的阶段。

　　**TinyML是一个新兴领域，是快速增长的机器学习技术和应用，是一片巨大的、未被充分开发的蓝海。**

对TinyML做个简单总结：

　　**• What：**TinyML是指超低功耗（毫瓦量级）的边缘侧机器学习应用。

　　**• Why：**TinyML可以提升大量物联网设备的数据分析和决策能力。

　　**• How：**TinyML的实现需要硬件、软件和算法的整体性协同设计。

　　**• When：**现在是着手布局TinyML的最好时机。



首先，我们需要明确的区分在物联网终端中应用机器学习的两种方式：

　　**• 为物联网终端设备提供机器学习服务**

　　**• 在物联网终端设备中内嵌TinyML即服务**

这两种表述看似相像，实则不同。

　　在第一种情况下，为物联网终端设备提供的机器学习服务，一般将所有ML任务都“外包”给边缘设备和云服务器，终端设备则以接收者的身份，“被动”执行由边缘和云端下发的各种任务。

　　在第二种情况下，物联网终端设备中内嵌TinyML即服务，“主动”参与智能决策与执行。虽然与云端和边缘相比，终端设备的资源非常有限，但TinyML即服务仍旧可以提升终端设备的分析能力，以便其能更好的处理实时物联网数据。

因此TinyML即服务，真正的实现了将机器学习带入到物联网终端。

看到这里，你或许有个疑问：机器学习生态系统非常庞大，而且对资源要求很高。物联网设备那么小，可以执行哪些机器学习任务？

　　为了更好的回答这个问题，我们先来说说TinyML和云端ML之间的差异，它们分别处于两个截然不同的世界。



当然，想要在终端物联网设备中，获得和云端ML同样的体验是不现实的。**TinyML主要实现的是推理（inference），也就是把从训练中学习到的能力，应用到实际操作中去。**



TinyML的出现，是为了更好的缓解边缘ML和云端ML中，无法突破的多种问题，包括数据隐私、网络带宽、时间延迟、可靠性和能源效率：



![img](../images/random_name/3ac79f3df8dcd1004ca7e1366aeace17b9122f52.jpeg)



此类改进同样适用于规模较大的模型，

在不降低模型准确率（accuracy）的同时，

实现机器学习模型效率数个数量级的提高。

例如，Microsoft 开发的 Bonsai 算法可小到 2 KB，

但比通常 40MB 的 kNN 算法或是 4MB 的神经网络具有更好的性能。

这个结果听上去可能无感，

但如果换句话说——在规模缩小了一万倍的模型上取得同样的准确率，这就十分令人印象深刻了。

规模如此小的模型，可以运行在 2KB 内存的 Arduino Uno 上。

简而言之，现在可以在售价 5 美元的微控制器上构建此类机器学习模型。



机器学习正处于一个交叉路口，两种计算范式齐头并进，

即以计算为中心的计算，和以数据为中心的计算。

在以计算为中心的计算范式下，数据是在数据中心的实例上存储和分析的；

而在以数据为中心的计算范式下，处理是在数据的原始位置执行的。

尽管在目前，以计算为中心的计算范式似乎很快会达到上限，但是以数据为中心的计算范式才刚刚起步。



以前，设备执行的各种操作必需基于复杂的集成电路。

现在，机器学习的硬件“智能”正逐渐抽象为软件，使得嵌入式设备更加简单、轻量级和灵活。



使用嵌入式设备实现机器学习，需解决巨大的挑战，但在该领域也取得了长足的进步。

在微控制器上部署神经网络，关键挑战在于低内存占用、功率受限和计算受限。

智能手机是最典型的 TinyML 例子。

手机一直处于主动聆听“唤醒词”的状态，

例如 Android 智能手机的“你好，谷歌”，以及 iPhone 的“你好，Siri”。

如果通过智能手机的 CPU（主流 iPhone 的 CPU 已达 1.85 GHz）运行语音唤醒服务，那么电池电量会在短短几个小时内耗尽。

这样的电量消耗是不可接受的，而语音唤醒服务大多数人每天最多使用几次。



在一台智能手机中，唤醒词服务并非唯一无缝嵌入的 TinyML 应用。

加速度计数据可用于确定用户是否刚拿起手机，进而唤醒 CPU 并点亮屏幕。



显然，这些并非 TinyML 的唯一用武之地。

实际上，TinyML 为产品粉丝和企业提供了大量令人兴奋的应用，

用于实现更智能的 IoT 设备。

在当前数据变得越来越重要的情况下，

将机器学习资源分发到远端内存受限设备的能力，

为农业、天气预报或地震等数据密集行业提供了巨大机遇。

目前，TinyML 主要的两个重点应用领域是：

关键字发现。

大多数人已经非常熟悉此应用，例如“你好，Siri”和“你好，Google”等关键字，通常也称为“热词”或“唤醒词”。设备会连续监听来自麦克风的音频输入，训练实现仅响应与所学关键字匹配的特定声音序列。这些设备比自动语音识别（automatic speech recognition，ASR）更简单，使用更少的资源。Google 智能手机等设备还使用了级联架构实现扬声器的验证，以确保安全性。

视觉唤醒词。

视觉唤醒词使用图像类似替代唤醒词的功能，通过对图像做二分类表示存在与否。例如，设计一个智能照明系统，在检测到人的存在时启动，并在人离开时关闭。同样，野生动物摄影师可以使用视觉唤醒功能在特定的动物出现时启动拍摄，安防摄像机可以在检测到人活动时启动拍摄。



机器/深度学习已经如火如荼，各种炫目的效果呈现不穷，

笔者也复现一些如stackoverflow assistence、头像动漫化等，但大都需要强大算力，“终端（手机）+云服务器”是基本结构。

去年关注到Google TFLite Micro（TFLM）及技术，

可以将Tensorflow 模型部署到嵌入式的端末设备（比如arm cortex M4 64M）。

恰好手头有一个农业物联网项目，**利用嵌入式设备识别牲畜的活动状态**，应用了这一个技术。

这段时间项目间隙，记录下开发过程的一些心得体会。



推荐《TinyML: Machine Learning with TensorFlow Lite on  Arduino and Ultra-Low-Power Microcontrollers》这本书，有中文版。

该书从背景、理论阐述TinyML，并且”show me the code”，

从四个具体例子：Hello World、唤醒词检测、行人检测、魔杖进行讲述。



需要的软件

基于Tensorflow lite for microcontroller框架，位于tensorflow源码中；

ide推荐vs code；



对于Tensorflow最大需求是能够在桌面系统中训练并运行模型，

这种需求影响了很多设计决策，

例如为了更低的延迟和更多的功能而增加可执行文件的大小。

云端服务器上，RAM以GB为衡量单位，存储空间以TB为单位，几百兆字节的二进制文件通常不是问题。



不过，这些工程上的取舍不适用于其他平台（Android、IOS以及嵌入式平台），哪怕是将应用程序大小仅仅增加几兆字节也会大大减少下载次数并降低客户的满意度。

你可以为这些手机平台编译TensorFlow，但是默认情况下，会使应用程序至少增加20MB，即使一些优化也很难减少到2MB以下。   

  Google在2017年启动了TensorFlow Lite，

目标是在移动设备上高效且轻松的运行神经网络模型。

为了减少框架的大小和复杂性，TFLite 删除了不常用的功能。

**例如，它不支持训练模型，而是仅支持模型运行推断。**

它还不支持TF主线中可用的全部数据类型（例如double）。

**此外，TFLite也不支持一些使用次数比较少的算子。**

  作为这些折中的回报，TFLite可以只用几百字节，从而使其更适合大小受到限制的应用程序。

它还为Arm Cortex-A 系列CPU提供了高度优化的库。

另外一个关键有点是TFLite对网络的8位量化有很好支持。

一个模型有数百万个参数，仅仅是从32位浮点数转换为8位整数就能减少75%的大小。

  **简单的说，TFLite与TF最大的不同，它只关注推断。**



嵌入式环境运行前提对TFLM需求

1）没有操作系统依赖项

有些目标平台根本没有操作系统

2）链接时没有标准的C或C++库依赖项

为了节省空间，**比如sprintf()简单的函数要占用20KB空间**，唯一例外的是标准的c math库。

3）不需要浮点硬件

没话说，便宜的mcu说硬件浮点要贵2块钱，再买一个不香吗？

4）没有动态内存分配

运行需要连续运行需要连续几个月或者几年，如果主循环用malloc()/new 和free()/delete来分配和释放内存，难免堆最终不会以碎片状态结束。所以，tflm干脆要求传入一个固定大小的内存空间，让框架在初始化时进行临时分配(如果太小，tflite会马上报错，再调整较大空间），除此之外执行推断将不会有进一步的内存分配需求，因此可以调用而不会有堆碎片或内存错误。

5）C++ 11

为了模块化代码方便维护，另外和TFLite 移动设备方面更轻松的共享代码





# 参考资料

1、

https://blog.csdn.net/wfing/article/details/106995562

2、一文读懂即将引爆的TinyML：在边缘侧实现超低功耗机器学习

http://www.ziwuiot.com/jishu/26288.html

3、TinyML：下一轮人工智能革命

https://baijiahao.baidu.com/s?id=1682409135667826022&wfr=spider&for=pc

4、TinyML实践-1：What & Why TinyML？

flavorfan的系列文章

https://cloud.tencent.com/developer/article/1757386
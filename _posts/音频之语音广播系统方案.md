---
title: 音频之语音广播系统方案
date: 2020-02-17 14:44:51
tags:
	- 音频

---

1

rtsp音频推流

最关键是服务器的搭建。



nginx rtmp服务器搭建

采用编译源码的方式。

从github下载stable的1.16版本。

https://github.com/nginx/nginx/tree/branches/stable-1.16

apt-get安装的nginx版本是1.10版本的。

用apt-get的方式安装了。

不行，要使用rtmpmodule，必须使用编译的方式。

需要先安装ssl的。

```
apt-get install libssl-dev
```

重新配置。

```
./configure --prefix=/usr/local/nginx --add-module=/root/work/rtmp_server/nginx-rtmp-module-master --with-http_ssl_module
```

默认的安装路径是：

```
/usr/local/nginx/
```

在/etc/profile.d里把这个加到PATH环境变量里。

配置文件在/usr/local/nginx/conf/nginx.conf

在这个文件里，跟http并列，增加一个rtmp。

```
rtmp {
	server {
		listen 1935;
		chunk_size 4000;
		application alive {
			live on;
			record off;
		}
	}
}
```

先来个简单的。

服务器启动：

```
ffmpeg -re -i ./test.mp4 -vcodec copy -acodec copy -f flv rtmp://teddyxiong53.ml:1935/alive/test
```

电脑上用vlc，点播串流：

```
rtmp://teddyxiogn53.ml/alive/test
```

现在是出错了。

把上面的域名改成ip地址就可以通了。

```
ffmpeg -re -i ./test.mp4 -vcodec copy -acodec copy -f flv rtmp://120.24.238.146:1935/alive/test
```

访问的地址也用ip的：

```
rtmp://120.24.238.146/alive/test
```

这就可以在本地电脑用vlc播放服务器上的rtsp媒体流了。

当前我是放了一个mp4文件上去的。

现在这样只是实现了一半的。

现在要实现从我的电脑，把媒体流推送到服务器，然后又用vlc从服务器把这个媒体流取下来播放。

就是需要修改ffmpeg这条命令。

```
ffmpeg -re -i ./test.mp4 -vcodec copy -acodec copy -f flv rtmp://120.24.238.146:1935/alive/test
```

当前这个是从服务器本地文件取数据，现在就是要把test.mp4替换成一个流地址。

如果数据来源的ip地址是公网可见的，那么直接把-i的参数改成这样：

```
-i rtsp://username:password@ip:port/xxx
```

这样就可以了。

但是，按道理，服务器不能主动连接到设备，因为设备的ip是私有的。



rtsp如何通过rtmp协议推送到服务端？

本地发送rtsp流，是靠ffmpeg来做？还是靠vlc来做？

应该是用ffmpeg。



我知道了，应该是在录音设备上执行ffmpeg，推送目标为rtmp服务器（公网ip）。

测试了一下，果然可以正常点播到。



现在看看正式的，应该怎么来做。

```
录音设备
	用ffmpeg代码来写。
	按键触发发送，这个先开始发送数据给服务器。并publish一个消息给mqtt服务器，说明已经开始传输音频数据了。
服务器
	1、配置好rtmp服务器即可。没有什么特别需要注意的。
	2、同时需要mqtt服务器，给所有的订阅者（播放设备）触发开始从本rtmp服务器开始拉取数据。
播放设备
	收到mqtt消息，开始从服务器拉取rtsp数据。
	这个也用ffmpeg代码来写吧。
```



先把alsa的音频数据可以通过rtmp点播到。

下面的命令，可以正常通过vlc用rtmp链接进行播放。

```
dd if=/dev/video0 bs=512K | ffmpeg -re -ar 48000 -ac 1 -acodec pcm_s16le -f s16le -ac 1 -i /dev/zero -f h264 -i - -vcodec copy -acodec aac -ab 128k -g 50 -strict -2 -f flv rtmp://120.24.238.146:1935/alive/test
```

但是实际上视频的图像并没有出来。

我不需要视频的。把上面命令简化一下。只传递音频的。

去掉一些参数，就怎么都不行。

所以需要先分析一下上面的参数的具体含义。

```
-re
	Read input at native frame rate
	读取输入。re表示read。
	主要用来模拟实时输入流。
	不用用在真的输入流上。
	默认情况下，ffmpeg是尽快把输入都读取进来的。
	加上这个选项，就会细水长流的方式来读取。
-f
	Force input or output file format
	可以是输入格式，也可以是输出格式。
	对于输入，会自动检测。
	对于输出，会根据后缀进行推测。
	所以大部分情况不需要-f参数。
-
	上面在-i后面有一个单独的“-”，这个表示上面意思？
	是管道命令的某个内容？
	不用管。我不用这个就是了。
-vcodec copy -acodec aac
	这个表示对视频数据直接传递（因为已经经过了编码了）
	对于音频数据，用aac编码。
```





用这个命令查看摄像头的信息。

```
v4l2-ctl -d  /dev/video0 --all
```



经过反复实验，得到传递alsa数据的命令是这样：

```
ffmpeg -f alsa -ac 1 -i hw:1,0 -acodec aac -ab 48k -ac 1 -f flv  rtmp://120.24.238.146:1935/alive/test
```

有这么几点在我意料之外的：

```
1、要-ac 1 写在-i前面，应该表示全局的意思。
	不然会提示-ac为2失败。
2、-f flv
	目前我只看到用这个成功的。其他的没有试过。
```

-f后面跟一个合法的AVOutputFormat，在libavdevice/alldevices.c里。

另外libavformat/allformats.c里。

那么现在要搞清楚的一个问题就是：aac音频编码，用什么方式来进行封装比较合适？

可以mp4来封装。

不过一般为了避免视频播放器来把自动处理这些音频文件，我们系统用m4a来做后缀。



flv这个封装格式，跟mp4有什么不同？主要应用场景是什么？

flv的特点是：体积小、视频质量好。

flv是flash video的缩写。

http://cn.wondershare.com/mp4/flv-vs-mp4.html



在buildroot里，因为默认先--disable-everything了。去掉这个选项，大部分的选项都打开了。够用了。



我的Ubuntu默认安装的，没有使能mp3的。进行编译安装了。



我当前就用aac编码，flv封装的来做。

目前用一块板子做录音端，我的Ubuntu笔记本电脑做播放端。

测试了一下效果。



# 树莓派推流直播

看看树莓派的推流直播方案有哪些，看看有没有参考价值。

有这些方法：

## raspivid

这个的延时大概170ms。

```
raspivid -t 0 -w 1280 -h 720 -fps 20 -o - | nc -k -l 8090
```

接收的那边，用mplayer工具，同一个局域网内。

```
mplayer -fps 20 -demuxer h264es ffmpeg://tcp://ip_addr:8090
```

## mjpeg-streamer



参考资料

1、互联网音频传输解决方案

http://www.ipaudio.com.cn/blog/daa04006e66

2、RTSP推流方案调优

https://www.jianshu.com/p/150f2c173960

3、FFmpeg 代码实现流媒体推流（RTSP）

https://www.jianshu.com/p/a9c7b08be46e

4、绝了！直播技术体系结构一篇通！速看！

https://zhuanlan.zhihu.com/p/27250731

5、

参考这个进行了编译。

https://blog.csdn.net/qq_20500811/article/details/100710441

6、rtsp实时流通过rtmp推送到服务端

https://www.cnblogs.com/wanggang123/p/5853731.html

7、Youtube streaming with audio using ffmpeg. Alsa buffer xrun

参考这篇文章的命令，可以让alsa正常通过rtmp直播到。

https://www.raspberrypi.org/forums/viewtopic.php?t=100987

8、

https://www.acmesystems.it/ffmpeg

9、android平台下基于ffmpeg采集Camera数据编码成H.264推流到RTMP服务器.md

https://github.com/byhook/ffmpeg4android/blob/master/readme/android%E5%B9%B3%E5%8F%B0%E4%B8%8B%E5%9F%BA%E4%BA%8Effmpeg%E9%87%87%E9%9B%86Camera%E6%95%B0%E6%8D%AE%E7%BC%96%E7%A0%81%E6%88%90H.264%E6%8E%A8%E6%B5%81%E5%88%B0RTMP%E6%9C%8D%E5%8A%A1%E5%99%A8.md

10、使用树莓派进行24小时视频直播

https://blog.csdn.net/weixin_33711647/article/details/91476981
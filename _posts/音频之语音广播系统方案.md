---
title: 音频之语音广播系统方案
date: 2020-02-17 14:44:51
tags:
	- 音频

---

1

rtsp音频推流

最关键是服务器的搭建。



nginx rtmp服务器搭建

采用编译源码的方式。

从github下载stable的1.16版本。

https://github.com/nginx/nginx/tree/branches/stable-1.16

apt-get安装的nginx版本是1.10版本的。

用apt-get的方式安装了。

不行，要使用rtmpmodule，必须使用编译的方式。

需要先安装ssl的。

```
apt-get install libssl-dev
```

重新配置。

```
./configure --prefix=/usr/local/nginx --add-module=/root/work/rtmp_server/nginx-rtmp-module-master --with-http_ssl_module
```

默认的安装路径是：

```
/usr/local/nginx/
```

在/etc/profile.d里把这个加到PATH环境变量里。

配置文件在/usr/local/nginx/conf/nginx.conf

在这个文件里，跟http并列，增加一个rtmp。

```
rtmp {
	server {
		listen 1935;
		chunk_size 4000;
		application alive {
			live on;
			record off;
		}
	}
}
```

先来个简单的。

服务器启动：

```
ffmpeg -re -i ./test.mp4 -vcodec copy -acodec copy -f flv rtmp://teddyxiong53.ml:1935/alive/test
```

电脑上用vlc，点播串流：

```
rtmp://teddyxiogn53.ml/alive/test
```

现在是出错了。

把上面的域名改成ip地址就可以通了。

```
ffmpeg -re -i ./test.mp4 -vcodec copy -acodec copy -f flv rtmp://120.24.238.146:1935/alive/test
```

访问的地址也用ip的：

```
rtmp://120.24.238.146/alive/test
```

这就可以在本地电脑用vlc播放服务器上的rtsp媒体流了。

当前我是放了一个mp4文件上去的。

现在这样只是实现了一半的。

现在要实现从我的电脑，把媒体流推送到服务器，然后又用vlc从服务器把这个媒体流取下来播放。

就是需要修改ffmpeg这条命令。

```
ffmpeg -re -i ./test.mp4 -vcodec copy -acodec copy -f flv rtmp://120.24.238.146:1935/alive/test
```

当前这个是从服务器本地文件取数据，现在就是要把test.mp4替换成一个流地址。

如果数据来源的ip地址是公网可见的，那么直接把-i的参数改成这样：

```
-i rtsp://username:password@ip:port/xxx
```

这样就可以了。

但是，按道理，服务器不能主动连接到设备，因为设备的ip是私有的。



rtsp如何通过rtmp协议推送到服务端？

本地发送rtsp流，是靠ffmpeg来做？还是靠vlc来做？

应该是用ffmpeg。



我知道了，应该是在录音设备上执行ffmpeg，推送目标为rtmp服务器（公网ip）。

测试了一下，果然可以正常点播到。



现在看看正式的，应该怎么来做。

```
录音设备
	用ffmpeg代码来写。
	按键触发发送，这个先开始发送数据给服务器。并publish一个消息给mqtt服务器，说明已经开始传输音频数据了。
服务器
	1、配置好rtmp服务器即可。没有什么特别需要注意的。
	2、同时需要mqtt服务器，给所有的订阅者（播放设备）触发开始从本rtmp服务器开始拉取数据。
播放设备
	收到mqtt消息，开始从服务器拉取rtsp数据。
	这个也用ffmpeg代码来写吧。
```



先把alsa的音频数据可以通过rtmp点播到。

下面的命令，可以正常通过vlc用rtmp链接进行播放。

```
dd if=/dev/video0 bs=512K | ffmpeg -re -ar 48000 -ac 1 -acodec pcm_s16le -f s16le -ac 1 -i /dev/zero -f h264 -i - -vcodec copy -acodec aac -ab 128k -g 50 -strict -2 -f flv rtmp://120.24.238.146:1935/alive/test
```

但是实际上视频的图像并没有出来。

我不需要视频的。把上面命令简化一下。只传递音频的。

去掉一些参数，就怎么都不行。

所以需要先分析一下上面的参数的具体含义。

```
-re
	Read input at native frame rate
	读取输入。re表示read。
	主要用来模拟实时输入流。
	不用用在真的输入流上。
	默认情况下，ffmpeg是尽快把输入都读取进来的。
	加上这个选项，就会细水长流的方式来读取。
-f
	Force input or output file format
	可以是输入格式，也可以是输出格式。
	对于输入，会自动检测。
	对于输出，会根据后缀进行推测。
	所以大部分情况不需要-f参数。
-
	上面在-i后面有一个单独的“-”，这个表示上面意思？
	是管道命令的某个内容？
	不用管。我不用这个就是了。
-vcodec copy -acodec aac
	这个表示对视频数据直接传递（因为已经经过了编码了）
	对于音频数据，用aac编码。
```





用这个命令查看摄像头的信息。

```
v4l2-ctl -d  /dev/video0 --all
```



经过反复实验，得到传递alsa数据的命令是这样：

```
ffmpeg -f alsa -ac 1 -i hw:1,0 -acodec aac -ab 48k -ac 1 -f flv  rtmp://120.24.238.146:1935/alive/test
```

有这么几点在我意料之外的：

```
1、要-ac 1 写在-i前面，应该表示全局的意思。
	不然会提示-ac为2失败。
2、-f flv
	目前我只看到用这个成功的。其他的没有试过。
```

-f后面跟一个合法的AVOutputFormat，在libavdevice/alldevices.c里。

另外libavformat/allformats.c里。

那么现在要搞清楚的一个问题就是：aac音频编码，用什么方式来进行封装比较合适？

可以mp4来封装。

不过一般为了避免视频播放器来把自动处理这些音频文件，我们系统用m4a来做后缀。



flv这个封装格式，跟mp4有什么不同？主要应用场景是什么？

flv的特点是：体积小、视频质量好。

flv是flash video的缩写。

http://cn.wondershare.com/mp4/flv-vs-mp4.html



在buildroot里，因为默认先--disable-everything了。去掉这个选项，大部分的选项都打开了。够用了。



我的Ubuntu默认安装的，没有使能mp3的。进行编译安装了。



我当前就用aac编码，flv封装的来做。

目前用一块板子做录音端，我的Ubuntu笔记本电脑做播放端。

测试了一下效果。



# 树莓派推流直播

看看树莓派的推流直播方案有哪些，看看有没有参考价值。

有这些方法：

## raspivid

这个的延时大概170ms。

```
raspivid -t 0 -w 1280 -h 720 -fps 20 -o - | nc -k -l 8090
```

接收的那边，用mplayer工具，同一个局域网内。

```
mplayer -fps 20 -demuxer h264es ffmpeg://tcp://ip_addr:8090
```

## mjpeg-streamer





ffmpeg直播，总的来说，有以下两种方式：

1、要么传递到某个服务器上，由服务器进行转发给多个client。

2、直接传递给对应的client。

一般是采用服务器中转的方式。

这种方式比较灵活。

那么哪些服务器软件可以做这个事情呢？

1、ffmpeg自带的ffserver就可以。

2、vlc也可以进行转发。

3、nginx带rtmp插件。



-re这个选项

表示用native帧率读取input。

主要用来模拟一个grab device。

例如你是stream一个视频文件，你就需要用到这个选项。

否则可能会很快传输。

例如你一个一分钟的视频文件，如果不加这个选项，可能在几秒钟就传递完了。

但是对于摄像头设备，你就不需要用这个选项了。

这个是直播了笔记本的显示屏。

```
ffmpeg -f x11grab -s 1366x768 -framerate 15 -i :0.0 -c:v libx264 -preset fast \
	-pix_fmt yuv420p -s 1366x768 -f flv "rtmp://120.24.238.146:1935:/alive/test" 
```

延迟比较大。

这个是直播实时声音的。

```
ffmpeg -f alsa -ac 2 -i hw:0,0  \
-c:a aac -b:a 128k -ar 44100 \
-f flv rtmp://120.24.238.146:1935/alive/test
```



这个命令在笔记本上执行后，通过vlc保存音频下来，是没有声音的。

```
ffmpeg -f alsa -ac 2 -i hw:0,0 -ac 2 -ar 44100 -c:a libmp3lame -b:a 128k -f flv rtmp://120.24.238.146:1935/alive/test
```



试一下srs这个直播服务器端软件。

国人写的开源软件。试了，效果跟nginx的差不多。



现在测试环境拓扑结构是：

```
树莓派  ---> 笔记本 <--- 手机
```

树莓派提供直播数据。

手机充当播放器。

放了大概100秒左右，树莓派这边就出错退出了。

说写到了文件尾部。这个怎么理解？

```
av_interleaved_write_frame(): End of file  34.5kbits/s speed=   1x    
[flv @ 0x20c7d20] Failed to update header with correct duration.
[flv @ 0x20c7d20] Failed to update header with correct filesize.
Error writing trailer of rtmp://172.16.4.205:1935/alive/test: End of file
size=     527kB time=00:02:05.24 bitrate=  34.5kbits/s speed=   1x    
video:0kB audio:490kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 7.655453%
Conversion failed!
```

https://trac.ffmpeg.org/ticket/7547

这里提到了类似的问题。

现在在我们的板子上运行这个命令。开始我把buffer设置为32K的，很快也出错了。改成128k看看。

```
 ffmpeg -f alsa -ac 8 -i hw:0,0 -ac 1 -ar 48000 -c:a libmp3lame -b:a 128k -f
flv  rtmp://172.16.4.205:1935/alive/test
```

现在放了十几分钟，没有出现问题。



看libavformat/rtmpproto.c。

看到有rtmp_live这个选项。这个选项具体代表了什么？

怎么使用这个选项？没有什么用。



先不考虑延迟的，目前数据是通的。

模式上有什么问题？

1、如果一直连接，数据量还比较大。没有必要。

2、如果不连接，用的时候才连接，这个延迟就更大了。

还是用的时候再连接比较稳妥。

但是如果这样，还不如先录音成文件，直接从服务端推文件。



# 再思考

回到问题的本质，我要做的是，Linux实时语音。

以这个为关键词进行搜索。

https://wenku.baidu.com/view/ab24b849852458fb770b56f2.html?sxts=1583220445364

这篇文章，是提到用live库，自己封装alsa数据来进行通信。

https://wenku.baidu.com/view/fa715c58be23482fb4da4cae.html?sxts=1583220651934

直接通过socket，收发pcm数据。

是否经过服务器中转数据？

语音系统，不要采用tcp的方式，而是用udp。稍微丢一些数据不影响通话效果。

udp可以提高实时性。

但是rtmp就是基于tcp的。

```
当然RTMP协议也有一些局限，RTMP基于TCP协议，而TCP协议实时性不如UDP，也非常占用带宽。
```

目前常见的直播方案都是上行采用rtmp；下行采用http-flv或者hls，底层都是tcp。

利用rtmp协议可以很快搭建一套直播系统，客户端、服务器都有成熟稳定的开源实现。

UDP理论上更适合用于直播系统，但开发效率低，周期长。

网上当前找到的，大部分都是没有通过服务器中转的方式，根本不具备实用性。

方案估计还是得沿着之前的路往前走。

1、服务端不动了。就用nginx-rtmp的。



客户端，能不能用gstreamer呢？

https://blog.csdn.net/zhaoyun_zzz/article/details/86496621



搜索“Linux live audio ffmpeg”。



icecast

音频流服务器 *Icecast*2

流媒体的网络电台



整个逻辑，是不是这样比较妥当：

需要实时讲话的时候，也是类似微信语音消息一下，说完之后再把文件发送到服务器，然后通知所有的客户端进行播放对应的url。

这样就比较简单了。



参考资料

1、互联网音频传输解决方案

http://www.ipaudio.com.cn/blog/daa04006e66

2、RTSP推流方案调优

https://www.jianshu.com/p/150f2c173960

3、FFmpeg 代码实现流媒体推流（RTSP）

https://www.jianshu.com/p/a9c7b08be46e

4、绝了！直播技术体系结构一篇通！速看！

https://zhuanlan.zhihu.com/p/27250731

5、

参考这个进行了编译。

https://blog.csdn.net/qq_20500811/article/details/100710441

6、rtsp实时流通过rtmp推送到服务端

https://www.cnblogs.com/wanggang123/p/5853731.html

7、Youtube streaming with audio using ffmpeg. Alsa buffer xrun

参考这篇文章的命令，可以让alsa正常通过rtmp直播到。

https://www.raspberrypi.org/forums/viewtopic.php?t=100987

8、

https://www.acmesystems.it/ffmpeg

9、android平台下基于ffmpeg采集Camera数据编码成H.264推流到RTMP服务器.md

https://github.com/byhook/ffmpeg4android/blob/master/readme/android%E5%B9%B3%E5%8F%B0%E4%B8%8B%E5%9F%BA%E4%BA%8Effmpeg%E9%87%87%E9%9B%86Camera%E6%95%B0%E6%8D%AE%E7%BC%96%E7%A0%81%E6%88%90H.264%E6%8E%A8%E6%B5%81%E5%88%B0RTMP%E6%9C%8D%E5%8A%A1%E5%99%A8.md

10、使用树莓派进行24小时视频直播

https://blog.csdn.net/weixin_33711647/article/details/91476981

11、

https://www.cnblogs.com/remember-forget/p/10372983.html

12、音视频开发---ffmpeg rtmp推流

https://blog.csdn.net/u011734326/article/details/97920272

13RTMP推流及协议学习

https://blog.csdn.net/lory17/article/details/61916351?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
---
title: mmu学习
date: 2017-04-15 11:00:41
tags:
	- mmu
---
高性能的处理器一般都会提供一个内存管理单元，简称是MMU。
MMU的作用有：

* 辅助os进行内存管理。
* 提供虚拟地址和物理地址的映射。
* 内存访问权限控制。
* cache缓存控制。

要理解MMU的原理，我们先得明白几个概念。
* TLB
  是Translation Lookaside Buffer，转换旁路缓存。这个是MMU的核心部件。它用来缓存少量的虚拟地址和物理地址的转换关系，是转换表的cache，一般叫做“快表”。
* TTW
  是Translation Table Walk，转换表漫游，这是一种行为。如果再TLB里没有找到地址转换时，需要通过对DDR里的转换表（一般是2级的）的查询来得到虚拟地址和物理地址的对应关系，这种行为就叫TTW。TTW成功之后，会把内容刷到TLB里。方便下次访问。

ARM里有DTLB和ITLB这种指令，用查做TLB相关的操作。

ARM 支持的存储块的大小有这4种：
段（Section）：1MB。
大页（Large Page）：64KB。
小页（Small Page）：4KB。
极小页（Tiny Page）：1KB。

每个用户进程有自己的页表。

内存的申请：
对于用户空间，就是malloc和free了。
内核空间的话，例如在驱动里申请内存，有这些：

```
kmalloc()：得到的空间在物理上是连续的。底层是用__get_free_pages()来实现。一般申请时用的flag是GFP_KERNEL，用这个标志的时候，如果当前申请不到，会睡眠，如果不想睡眠，就要用GFP_ATOMIC的flag来申请。
__get_free_pages()：得到的空间在物理上是连续的。申请单位是以页为单位。
vmalloc()：不是连续的空间。开销较大，少量内存不要用这个来分配。因为会出发页表重新建立。
slab和内存池：
如果以页为单位来分配内存，无疑浪费很大，而os运行过程中，有大量的对象重复生成，例如inode、task_struct这种对象，如果可以做到对象前后两次被使用的时候，分配在同一块内存地址并且保留了基本的数据结构，可以极大地提高效率。
```



mmu由cp15协处理器的寄存器1的M位来决定是打开还是关闭。

**如果mmu没有或者被关闭，那么CPU发出的地址，直接就传到了地址总线上。直接被ddr芯片接收。**

这个地址就是物理地址。

如果启用了mmu，CPU发出的地址会被mmu拦截，

打开mmu之后的一次寻址，实际是产生了3次内存访问，效率肯定是下降了。

地址转换过程，mmu硬件自动完成。

整个过程分解如下：

1、cpu发出寻址请求，MMU的TLB（这个是mmu内部的一个缓存，缓存一部分的映射关系）接受到请求。

TLB查询页表项，页表项里存着权限和是否cache的标志呢。

如果没有权限，直接返回异常给CPU。如果有权限，就检查是否是cache的。

是cache的，就让 cpu跟cache去商量一下。看看cache里有没有，没有的话，去访问ddr。

如果不允许cache的，例如寄存器的都不允许cache。那就直接访问目标地址。



```
/*
 * CR1 bits (CP#15 CR1)
 */
#define CR_M	(1 << 0)	/* MMU enable				*/
```



# mmu和cache的关系

必须使能mmu，才能用cache。





# 参考资料

1、MMU和cache详解（TLB机制）

https://blog.csdn.net/qq_21792169/article/details/51303477
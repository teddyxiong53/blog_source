---
title: npu之NNAPI
date: 2021-08-27 13:25:33
tags:
	- npu

---

--

Android Neural Networks API (NNAPI) 

是一个基于 Android 系统的

用于可在移动设备上运行与机器学习相关的

计算密集型操作的 C 语言 API，

NNAPI 将为更高层次的可构建和训练神经网络的机器学习框架

（如 TensorFLow Lite, Caffe2, 等等）

提供底层支持。

这些 API 将会集成到所有的 Android 8.1 （以及更高版本）设备上。



AI 应用的本地化，即把 AI 运算直接在移动设备上执行，不需要通过网络与云端交互的好处有以下几点：

- **低延时：** 你不再需要通过网络与云端交互，并且等待服务器响应。这对于需要成功地实时地从相机获得连续帧的视频应用来说是至关重要的。
- **有效性：** 应用也可在网络覆盖不到的地方使用。
- **快：** 相比只用 cpu 作为处理器来说，一些新的硬件加速器，如神经网络处理器可以提供更快的运行速度。
- **私密性：** 这些数据只存在于本地设备上。
- **低成本：** 当所有的 AI 运算都在本地设备上执行时，将不再需要服务器群组。



NNAPI 基本就是提供给机器学习库和机器学习框架在 Android 设备上调用的。

App 不能直接使用 NNAPI，

但可通过更高级别的机器学习框架间接地使用。

这些机器学习框架可通过 NNAPI 使用指定的硬件加速器。



基于 app 的需求和移动设备上的硬件能力，

Android 的神经网络运行时能很好地根据给定的硬件分配各自的计算量，

包括专用的神经网络硬件，图像处理单元(GPU)，以及数字信号处理器(DSP)。



在一些没有硬件加速器的设备上，NNAPI 运行时会以优化代码的方式把这些 AI 运算放到 CPU 上运行。



参考资料

1、Android 之AI硬件和NNAPI介绍

https://blog.csdn.net/qkhhyga2016/article/details/78800912
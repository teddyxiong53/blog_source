---
title: npu之使用较小数据集进行训练
date: 2021-09-27 14:34:33
tags:
	- npu

---

--

在本文中，我们将提供一些面向小数据集（几百张到几千张图片）构造高效、实用的图像分类器的方法。

本文将探讨如下几种方法：

- 从图片中直接训练一个小网络（作为基准方法）
- 利用预训练网络的bottleneck（瓶颈）特征
- fine-tune预训练网络的高层

本文需要使用的Keras模块有：

- `fit_generator`：用于从Python生成器中训练网络
- `ImageDataGenerator`：用于实时数据提升
- 层参数冻结和模型fine-tune



下面是数据集的一些示例图片，图片的数量非常少，这对于图像分类来说是个大麻烦。

但现实是，很多真实世界图片获取是很困难的，

我们能得到的样本数目确实很有限（比如医学图像，每张正样本都意味着一个承受痛苦的病人:(）。

对数据科学家而言，**我们应该有能够榨取少量数据的全部价值的能力，而不是简单的伸手要更多的数据。**

在Kaggle的猫狗大战竞赛种，参赛者通过使用现代的深度学习技术达到了98%的正确率，我们只使用了全部数据的8%，因此这个问题对我们来说更难。



我经常听到的一种说法是，深度学习只有在你拥有海量数据时才有意义。

虽然这种说法并不是完全不对，但却具有较强的误导性。

当然，深度学习强调从数据中自动学习特征的能力，没有足够的训练样本，这几乎是不可能的。

尤其是当输入的数据维度很高（如图片）时。

然而，卷积神经网络作为深度学习的支柱，被设计为针对“感知”问题最好的模型之一（如图像分类问题），即使只有很少的数据，网络也能把特征学的不错。

**针对小数据集的神经网络依然能够得到合理的结果，并不需要任何手工的特征工程。**

一言以蔽之，卷积神经网络大法好！

另一方面，深度学习模型天然就具有可重用的特性：

比方说，你可以把一个在大规模数据上训练好的图像分类或语音识别的模型重用在另一个很不一样的问题上，而只需要做有限的一点改动。

尤其在计算机视觉领域，许多预训练的模型现在都被公开下载，并被重用在其他问题上以提升在小数据集上的性能。



为了尽量利用我们有限的训练数据，我们将通过一系列随机变换堆数据进行提升，这样我们的模型将看不到任何两张完全相同的图片，这有利于我们抑制过拟合，使得模型的泛化能力更好。

在Keras中，这个步骤可以通过`keras.preprocessing.image.ImageGenerator`来实现，这个类使你可以：

- 在训练过程中，设置要施行的随机变换
- 通过`.flow`或`.flow_from_directory(directory)`方法实例化一个针对图像batch的生成器，这些生成器可以被用作keras模型相关方法的输入，如`fit_generator`，`evaluate_generator`和`predict_generator`

现在让我们看个例子：



思路就对已有图片进行一些简单的变换操作，来生成更多的图片作为训练材料。

keras提供的类是ImageDataGenerator。



进行图像分类的正确工具是卷积网络，所以我们来试试用卷积神经网络搭建一个初级的模型。

因为我们的样本数很少，所以我们应该对过拟合的问题多加注意。

当一个模型从很少的样本中学习到不能推广到新数据的模式时，我们称为出现了过拟合的问题。

过拟合发生时，模型试图使用不相关的特征来进行预测。

例如，你有三张伐木工人的照片，有三张水手的照片。

六张照片中只有一个伐木工人戴了帽子，如果你认为戴帽子是能将伐木工人与水手区别开的特征，那么此时你就是一个差劲的分类器。



数据提升是对抗过拟合问题的一个武器，但还不够，

**因为提升过的数据仍然是高度相关的。**

对抗过拟合的你应该主要关注的是模型的“熵容量”——模型允许存储的信息量。

能够存储更多信息的模型能够利用更多的特征取得更好的性能，但也有存储不相关特征的风险。

另一方面，只能存储少量信息的模型会将存储的特征主要集中在真正相关的特征上，并有更好的泛化性能。



有很多不同的方法来调整模型的“熵容量”，

常见的一种选择是调整模型的参数数目，

即模型的层数和每层的规模。

另一种方法是对权重进行正则化约束，如L1或L2.这种约束会使模型的权重偏向较小的值。



在我们的模型里，我们使用了很小的卷积网络，只有很少的几层，

每层的滤波器数目也不多。

再加上数据提升和Dropout，就差不多了。

Dropout通过防止一层看到两次完全一样的模式来防止过拟合，

相当于也是一种数据提升的方法。（你可以说dropout和数据提升都在随机扰乱数据的相关性）



一个稍微讲究一点的办法是，利用在大规模数据集上预训练好的网络。

这样的网络在多数的计算机视觉问题上都能取得不错的特征，

利用这样的特征可以让我们获得更高的准确率。



我们将使用vgg-16网络，该网络在ImageNet数据集上进行训练，这个模型我们之前提到过了。

因为ImageNet数据集包含多种“猫”类和多种“狗”类，

这个模型已经能够学习与我们这个数据集相关的特征了。

事实上，简单的记录原来网络的输出而不用bottleneck特征就已经足够把我们的问题解决的不错了。

不过我们这里讲的方法对其他的类似问题有更好的推广性，

包括在ImageNet中没有出现的类别的分类问题。



我们的方法是这样的，我们将利用网络的卷积层部分，

把全连接以上的部分抛掉。

然后在我们的训练集和测试集上跑一遍，

**将得到的输出（即“bottleneck feature”，网络在全连接之前的最后一层激活的feature map）记录在两个numpy array里。**

**然后我们基于记录下来的特征训练一个全连接网络。**

```python
generator = datagen.flow_from_directory(
        'data/train',
        target_size=(150, 150),
        batch_size=32,
        class_mode=None,  # this means our generator will only yield batches of data, no labels
        shuffle=False)  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs
# the predict_generator method returns the output of a model, given
# a generator that yields batches of numpy data
bottleneck_features_train = model.predict_generator(generator, 2000)
# save the output as a Numpy array
np.save(open('bottleneck_features_train.npy', 'w'), bottleneck_features_train)
```

然后这样使用

```python
train_data = np.load(open('bottleneck_features_train.npy'))
```



参考资料

1、

https://keras-cn.readthedocs.io/en/latest/legacy/blog/image_classification_using_very_little_data/
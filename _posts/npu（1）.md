---
title: npu（1）
date: 2021-08-18 16:33:33
tags:
	- npu

---

--

接下来的工作会涉及到npu。所以现在先学习一下基本知识。

# 学习路线

1、先了解一些npu涉及到哪些知识点。

2、感觉知识点比较多。还是先想办法可以实际操作一把。tensorflow是肯定要用到的。那就先从tensorflow入手。



# 芯片情况

Amlogic A311D是基于S922X的人工智能场景芯片，简单理解：A311D=S922X+NPU。

这套路跟瑞芯微的RK3300Pro如出一辙，都是用了第三方的NPU处理核心，封装进自家的SoC，就成了面向人工智能领域的通用型芯片。

S905D3的情况也是类似，S905D3算是一款新的A55架构处理器，集成了1.2TOPs算力的NPU。

外挂第三方NPU的方案其实并不新鲜，早在 RK3399Pro量产之前，我们就曾推出外挂独立NPU的RK3399和RK3328方案。虽然相比同一个封装，这种外置挂载芯片占用面积会更大一些，但是算力的调整也更方便，可按需选择。

不管是出于友商的压力，还是由于市场的需求，晶晨也确实是走出了这一步，尽管是采用“胶水方案” 但确实满足了人工智能和物联网（**AIoT**）场景下的功能需求。晶晨在家庭影音市场有很高的占有率，有着庞的大用户群体，就等于掌握了大量的用户数据， 相信后续会针对此场景做单独的优化处理，给我们带来更好的使用体验。



## 参考资料

https://zhuanlan.zhihu.com/p/265651398

# NPU概念

神经网络处理器（NPU）。只要理解了神经网络计算，理解NPU就会非常简单。



以CNN为例，CNN计算由大量的乘加计算（乘法累加计算）组成。

传统的CPU架构进行类似的累加计算，效率是非常低的。

与CPU相比，以英伟达为代表的GPU做类似的计算，效率会比CPU高很多。

然而，这只是与CPU相比较。

GPU由于要兼顾图像处理的任务，不可能针对神经网络计算进行特殊优化，

**而NPU是指专门针对神经网络计算进行特殊优化设计的处理器。**

可以这么理解，CPU也可以做图像处理的任务，但是由于图像处理的需求越来越大，

所以英伟达看准机会，针对图像处理做了专门的芯片，效率比CPU高的多。

久而久之，图像处理就由专门的图像处理芯片GPU来完成。

同样，现在刚好是神经网络，机器学习处理需求爆发的初期。

传统的CPU，GPU也可以做类似的任务，但是，针对神经网络特殊优化过的NPU单元，性能会比CPU，GPU高得多。

渐渐的，类似的神经网络任务也会由专门的NPU单元来完成。

之后，为什么NPU的效率会比CPU/GPU高很多呢？

**主要就是由于乘法累加计算导致的。**

这个乘法累加计算不是简单的乘法累加计算，而是有数据相关性的乘法累加计算。

这样，按照通用CPU的处理方法，就无法利用数据相关性的优势，导致增加无谓的IO访存。

而英伟达的做法，就是暴力的增加带宽，带来的副作用就是功耗增加。



嵌入式神经网络处理器（NPU）采用“数据驱动并行计算”的架构，特别擅长处理视频、图像类的海量多媒体数据。



如果前面有一条河，有桥可以渡河，有船可以渡河，有直升机可以渡河，还可以游泳渡河......，我们选择哪一种方式渡河快还舒服呢？这就是 NPU 的工作了，它会在手机里面模拟一遍所有可行的方法，然后挑选出一个优选方式。如果这种方式有 1 亿种的话，那么 NPU 可能就要计算 1 亿次，这是一个苦力活！

所以现在大家明白了，CPU 干的是脑力工作，就像公司的总经理；NPU 是做程序式的工作，就像工厂流水线上面的工人。

有了NPU之后，手机的AI性能就有了大幅提升，具体体现在哪些方面呢？

比如拍照方面，如果是以前的手机，需要手动调试光圈、色度等参数值等，让相机达到较好的拍照状态。但是现在不用了，有了AI功能之后，系统内置上千种场景拍照模式，通过相机识别实时场景，相机会在这些拍照模式当中，选择一个适合的模式进行拍照。所以，即使你不懂拍照，你也能拍出非常棒的照片。



## 参考资料

https://www.zhihu.com/question/346062227/answer/831193139



# Tengine

Tengine 是 OPEN AI LAB 推出的面向 AIoT 场景 的 AI 应用开发平台，

致力于解决 AIoT 产业链碎 片化问题，加速 AI 产业化落地。

Tengine 专为 AIoT 场景设计，同时具有跨平台、异构调度、芯片底层加速、超轻量无依赖、完整开发移植部署工具链几大特点。

Tengine 兼容多种操作系统和深度学习算法框架，简化和加速面向场景的 AI 算法在嵌入式边缘设备上快速迁移，以及实际应用部署落地。



# open ai lab

不是野鸡公司，是一个正规鸭公司。

arm中国联合另外三家公司包括地平线一起搞的。

主打开放的边缘aoit计算框架，

能够让用户不用关心底层的ai计算硬件差异，

比如cpu，gpu，npu，dsp啥的，

前提是它的框架已经支持了你用的那块ai计算硬件，

如果你用的是主流硬件，比如华为的npu，瑞芯微的npu，amlogic的npu，主流gpu，cpu，大概率支持，

如果是非主流的，大概率不支持，

但它的目标是支持市面上所有主流的ai计算硬件。

对用户来说，好处是什么呢，如果你的硬件版本迭代了，ai计算单元的硬件改变了，用户的代码不用变，他帮你屏蔽了不同的计算芯片。

注册在上海的一家公司，成立于2016年，不到100人。


https://www.zhihu.com/question/306901455/answer/1676067544

# 参考资料

1、

http://www.ruiyixi.com/2019/10/10/amlogic%E7%9A%84ai%E4%B9%8B%E8%B7%AF%EF%BC%9A%E6%8E%A8%E5%87%BAa311d%E3%80%81s905d3%E7%AD%89%E5%86%85%E7%BD%AE%E7%8B%AC%E7%AB%8Bnpu%E7%9A%84%E9%80%9A%E7%94%A8%E5%9E%8Bsoc/